{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import shutil\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import ast\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import json\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet==3.0.4\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: chardet\n",
      "Successfully installed chardet-3.0.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting nltk==3.6.6\n",
      "  Downloading nltk-3.6.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.10/site-packages (from nltk==3.6.6) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.10/site-packages (from nltk==3.6.6) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.10/site-packages (from nltk==3.6.6) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from nltk==3.6.6) (4.66.1)\n",
      "Downloading nltk-3.6.6-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "Successfully installed nltk-3.6.6\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (1.24.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting xmltodict==0.12.0\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Installing collected packages: xmltodict\n",
      "Successfully installed xmltodict-0.12.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3.10 -m pip install chardet==3.0.4\n",
    "!python3.10 -m pip install nltk==3.6.6\n",
    "!python3.10 -m pip install numpy\n",
    "!python3.10 -m pip install pandas\n",
    "!python3.10 -m pip install xmltodict==0.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Reading Data variables\n",
    "labels = [\"B-EMAIL\", \"B-ID_NUM\", \"B-NAME_STUDENT\", \"B-PHONE_NUM\",\n",
    "          \"B-STREET_ADDRESS\", \"B-URL_PERSONAL\", \"B-USERNAME\",\n",
    "          \"I-ID_NUM\", \"I-NAME_STUDENT\", \"I-PHONE_NUM\",\n",
    "          \"I-STREET_ADDRESS\",\"I-URL_PERSONAL\",\"O\"]\n",
    "id2label = dict(enumerate(labels)) # integer label to BIO format label mapping\n",
    "label2id = {v:k for k,v in id2label.items()} # BIO format label to integer label mapping\n",
    "num_labels = len(labels) # number of PII (NER) tags\n",
    "BASE_PATH = \"./data/training_data/pii-detection-removal-from-educational-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING CUSTOM CONFIG\n",
    "with open(\"./configs/philter_delta.json\") as f:\n",
    "    config = json.load(f)\n",
    "    # titles below are from the philter config,in order, corresponding to the 'labels' given in the PII essays' data.\n",
    "    relevant_titles = [\"emails\", \"email header\",\n",
    "                      \"id safe\", \"id verbose\",\n",
    "                       \"six or more digits\", \"order number\", \"specimen number\", \"DDD-DD-DD\", \"DD-DDDDDC\", \"****DC\", \"model and serial numbers\",\n",
    "                       \"confirmed by name\", \"editor name\", \"name_age\", \"names patterns\", \"name indicator\", \"Find Names 1\", \"Find Names 2\", \"Find Names 3\", \"Find Names 4\",\n",
    "                       \"call #\", \n",
    "                       \"full street address\", \"full street address with concatenated street indicator\", \"number streetname city\", \"number streetname noindicator suite\", \"number streetname city state\", \"filters/regex/addresses/num_streetname_extension_transformed.txt\", \"number streetname san\", \"number streetname\", \"corner of street & street\", \"street and street\", \"at street number dash street\", \"at dash street\", \"short street name\", \"streetname floor number\", \"city state zip\", \"city zip\", \"lives in\", \"city state\", \"county name\", \"in city\", \"city\", \"box room\", \"room box\", \"floor box\", \"desk #\", \"at location\", \"to state\", \"state indicator\", \"on streetname\", \"box\", \"room\",\n",
    "                       \"url\", \n",
    "                       \n",
    "                      ]\n",
    "    relevant_config = []\n",
    "    for con in config:\n",
    "        if con[\"title\"] in relevant_titles:\n",
    "            relevant_config.append(con)\n",
    "    with open(\"./configs/philter_delta_relevant.json\", \"w\") as f_relevant:\n",
    "        json.dump(relevant_config, f_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c39ce7a07a4a749df6e11429f250be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6807 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train-Valid data\n",
    "data = json.load(open(f\"{BASE_PATH}/train.json\"))\n",
    "pii_external_dataset =pd.read_csv(f\"./data/training_data/pii-external-dataset/pii_dataset.csv\")\n",
    "data_mistral = json.load(open(f\"./data/training_data/pii-dd-mistral-generated/mixtral-8x7b-v1.json\"))\n",
    "data_mpware = json.load(open(\"./data/training_data/pii-mixtral8x7b-generated-essays/mpware_mixtral8x7b_v1.1.json\"))\n",
    "\n",
    "# Initialize empty arrays\n",
    "# words = np.empty(len(data) + len(pii_external_dataset) + len(data_mistral), dtype=object)\n",
    "texts = np.empty(len(data) + len(pii_external_dataset) + len(data_mistral) + len(data_mpware), dtype=object)\n",
    "# labels = np.empty(len(data) + len(pii_external_dataset) + len(data_mistral), dtype=object)\n",
    "\n",
    "# Fill the arrays\n",
    "for i, x in tqdm(enumerate(data), total=len(data)):\n",
    "    texts[i] = (x[\"full_text\"])\n",
    "#     words[i] = np.array(x[\"tokens\"])\n",
    "#     labels[i] = np.array([label2id[label] for label in x[\"labels\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pii_external_dataset : 4434\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of pii_external_dataset : {len(pii_external_dataset)}\")\n",
    "# Fill the arrays\n",
    "for ind in range(len(pii_external_dataset)):\n",
    "    x = pii_external_dataset.iloc[ind]\n",
    "    texts[ind + len(data)] = x[\"text\"]\n",
    "#     x_tokens_list = ast.literal_eval(x[\"tokens\"])\n",
    "#     x_labels_list = ast.literal_eval(x[\"labels\"])\n",
    "#     words[ind + len(data)] = np.array(x_tokens_list)\n",
    "#     labels[ind + len(data)] = np.array([label2id[label] for label in x_labels_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of mistral_dataset : 2355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bdb3e5f6b442478168989cb8392ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Length of mistral_dataset : {len(data_mistral)}\")\n",
    "for i, x in tqdm(enumerate(data_mistral), total=len(data_mistral)):\n",
    "#       print(np.array(x[\"tokens\"]))\n",
    "#       print(np.array([CFG.label2id[label] for label in x[\"labels\"]]))\n",
    "    texts[i + len(data) + len(pii_external_dataset)] = x[\"full_text\"]\n",
    "#     words[i + len(data) + len(pii_external_dataset)] = np.array(x[\"tokens\"])\n",
    "#     labels[i + len(data) + len(pii_external_dataset)] = np.array([label2id[label] for label in x[\"labels\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03be9692b40c47f2bb322150dd3e34b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, x in tqdm(enumerate(data_mpware), total=len(data_mpware)):\n",
    "#       print(np.array(x[\"tokens\"]))\n",
    "#       print(np.array([CFG.label2id[label] for label in x[\"labels\"]]))\n",
    "    texts[i + len(data) + len(pii_external_dataset) + len(data_mistral)] = np.array(x[\"full_text\"])\n",
    "    # labels[i + len(data) + len(pii_external_dataset) + len(data_mistral)] = np.array([CFG.label2id[label] for label in x[\"labels\"] if label != \"I-USERNAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/Akhil/GitHubRepos/philter-ucsf'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(\"./data/data_essays/essays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16288"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file :  5 / 16288\n"
     ]
    }
   ],
   "source": [
    "# Data creation\n",
    "if not os.path.exists(\"./data/data_essays\"):\n",
    "    os.mkdir(\"./data/data_essays\")\n",
    "if not os.path.exists(\"./data/data_essays/essays\"):\n",
    "    os.mkdir(\"./data/data_essays/essays\")\n",
    "if not os.path.exists(\"./data/data_essays/essays_results\"):\n",
    "    os.mkdir(\"./data/data_essays/essays_results\")\n",
    "for ind in range(len(texts)):\n",
    "    if ind != 0 and ind % 5 == 0:\n",
    "        print(\"Processing file : \", ind, \"/\", len(texts))\n",
    "        break\n",
    "    with open(f\"./data/data_essays/essays/essay_{ind:08d}.txt\", \"w\") as f:\n",
    "        f.write(texts[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['essay_00000004.txt',\n",
       " 'essay_00000002.txt',\n",
       " 'essay_00000003.txt',\n",
       " 'essay_00000001.txt',\n",
       " 'essay_00000000.txt']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./data/data_essays/essays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nChallenge & selection\\n\\nThe tool I use to help all stakeholders finding their way through the complexity of a project is the  mind map.\\n\\nWhat exactly is a mind map? According to the definition of Buzan T. and Buzan B. (1999, Dessine-moi  l'intelligence. Paris: Les Éditions d'Organisation.), the mind map (or heuristic diagram) is a graphic  representation technique that follows the natural functioning of the mind and allows the brain's  potential to be released. Cf Annex1\\n\\nThis tool has many advantages:\\n\\n•  It is accessible to all and does not require significant material investment and can be done  quickly\\n\\n•  It is scalable\\n\\n•  It allows categorization and linking of information\\n\\n•  It can be applied to any type of situation: notetaking, problem solving, analysis, creation of  new ideas\\n\\n•  It is suitable for all people and is easy to learn\\n\\n•  It is fun and encourages exchanges\\n\\n•  It makes visible the dimension of projects, opportunities, interconnections\\n\\n•  It synthesizes\\n\\n•  It makes the project understandable\\n\\n•  It allows you to explore ideas\\n\\nThe creation of a mind map starts with an idea/problem located at its center. This starting point  generates ideas/work areas, incremented around this center in a radial structure, which in turn is  completed with as many branches as new ideas.\\n\\nThis tool enables creativity and logic to be mobilized, it is a map of the thoughts.\\n\\nCreativity is enhanced because participants feel comfortable with the method.\\n\\nApplication & Insight\\n\\nI start the process of the mind map creation with the stakeholders standing around a large board  (white or paper board). In the center of the board, I write and highlight the topic to design.\\n\\nThrough a series of questions, I guide the stakeholders in modelling the mind map. I adapt the series  of questions according to the topic to be addressed. In the type of questions, we can use: who, what,  when, where, why, how, how much.\\n\\nThe use of the “why” is very interesting to understand the origin. By this way, the interviewed person  frees itself from paradigms and thus dares to propose new ideas / ways of functioning. I plan two  hours for a workshop.\\n\\nDesign Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nAfter modelling the mind map on paper, I propose to the participants a digital visualization of their  work with the addition of color codes, images and interconnections. This second workshop also lasts  two hours and allows the mind map to evolve. Once familiarized with it, the stakeholders discover  the power of the tool. Then, the second workshop brings out even more ideas and constructive  exchanges between the stakeholders. Around this new mind map, they have learned to work  together and want to make visible the untold ideas.\\n\\nI now present all the projects I manage in this type of format in order to ease rapid understanding for  decision-makers. These presentations are the core of my business models. The decision-makers are  thus able to identify the opportunities of the projects and can take quick decisions to validate them.  They find answers to their questions thank to a schematic representation.\\n\\nApproach\\n\\nWhat I find amazing with the facilitation of this type of workshop is the participants commitment for  the project. This tool helps to give meaning. The participants appropriate the story and want to keep  writing it. Then, they easily become actors or sponsors of the project. A trust relationship is built,  thus facilitating the implementation of related actions.\\n\\nDesign Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nAnnex 1: Mind Map Shared facilities project\\n\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"./data/data_essays/essays/essay_00000000.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['essay_00000004.txt',\n",
       " 'essay_00000002.txt',\n",
       " 'essay_00000003.txt',\n",
       " 'essay_00000001.txt',\n",
       " 'essay_00000000.txt',\n",
       " 'essay_00000004.xml',\n",
       " 'essay_00000003.xml',\n",
       " 'essay_00000002.xml',\n",
       " 'essay_00000000.xml',\n",
       " 'essay_00000001.xml']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./data/data_essays/essays_results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.dom.minidom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design Thinking for innovation reflexion-***** 2021-******** *****\n",
      "\n",
      "Challenge & selection\n",
      "\n",
      "The tool I use to help all stakeholders finding their way through the complexity of a project is the  mind map.\n",
      "\n",
      "What exactly is a mind map? According to the definition of ***** *. and ***** *. (1999, *******-***  l'intelligence. *****: Les É******* d'Organisation.), the mind map (or heuristic diagram) is a graphic  representation technique that follows the natural functioning of the mind and allows the brain's  potential to be released. Cf ******\n",
      "\n",
      "This tool has many advantages:\n",
      "\n",
      "•  It is accessible to all and does not require significant material investment and can be done  quickly\n",
      "\n",
      "•  It is scalable\n",
      "\n",
      "•  It allows categorization and linking of information\n",
      "\n",
      "•  It can be applied to any type of situation: **********, problem solving, analysis, creation of  new ideas\n",
      "\n",
      "•  It is suitable for all people and is easy to learn\n",
      "\n",
      "•  It is fun and encourages exchanges\n",
      "\n",
      "•  It makes visible the dimension of projects, opportunities, ****************\n",
      "\n",
      "•  It ***********\n",
      "\n",
      "•  It makes the project understandable\n",
      "\n",
      "•  It allows you to explore ideas\n",
      "\n",
      "The creation of a mind map starts with an idea/problem located at its center. This starting point  generates ideas/work areas, incremented around this center in a radial structure, which in turn is  completed with as many branches as new ideas.\n",
      "\n",
      "This tool enables creativity and ***** to be *********, it is a map of the thoughts.\n",
      "\n",
      "Creativity is enhanced because participants feel comfortable with the method.\n",
      "\n",
      "Application & Insight\n",
      "\n",
      "I start the process of the mind map creation with the stakeholders standing around a large board  (white or paper board). In the center of the board, I write and highlight the topic to design.\n",
      "\n",
      "Through a series of questions, I guide the stakeholders in modelling the mind map. I adapt the series  of questions according to the topic to be addressed. In the type of questions, we can use: who, what,  when, where, why, how, how much.\n",
      "\n",
      "The use of the “why” is very interesting to understand the origin. By this way, the interviewed person  ***** itself from ********* and thus dares to propose new ideas / ways of functioning. I plan two  hours for a workshop.\n",
      "\n",
      "Design Thinking for innovation reflexion-***** 2021-******** *****\n",
      "\n",
      "After modelling the mind map on paper, I propose to the participants a digital visualization of their  work with the addition of color codes, images and ****************. This second workshop also lasts  two hours and allows the mind map to evolve. Once ************ with it, the stakeholders discover  the power of the tool. Then, the second workshop brings out even more ideas and constructive  exchanges between the stakeholders. Around this new mind map, they have ******* to work  together and want to make visible the untold ideas.\n",
      "\n",
      "I now present all the projects I manage in this type of format in order to ease rapid understanding for  decision-makers. These presentations are the core of my business models. The decision-makers are  thus able to identify the opportunities of the projects and can take quick decisions to validate them.  They find answers to their questions thank to a schematic representation.\n",
      "\n",
      "Approach\n",
      "\n",
      "What I find ******* with the facilitation of this type of workshop is the participants commitment for  the project. This tool helps to give meaning. The participants appropriate the story and want to keep  writing it. Then, they easily become actors or sponsors of the project. A trust relationship is built,  thus facilitating the implementation of related actions.\n",
      "\n",
      "Design Thinking for innovation reflexion-***** 2021-******** *****\n",
      "\n",
      "Annex 1: Mind Map Shared facilities project\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xml_fname = './data/data_essays/essays_results/essay_00000000.xml'\n",
    "# dom = xml.dom.minidom.parse(xml_fname) # or xml.dom.minidom.parseString(xml_string)\n",
    "# pretty_xml_as_string = dom.toprettyxml()\n",
    "# print(pretty_xml_as_string)\n",
    "\n",
    "with open('./data/data_essays/essays_results/essay_00000000.txt') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 4332496,
     "sourceId": 7466758,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4379849,
     "sourceId": 7518925,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4459964,
     "sourceId": 7659420,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4779069,
     "sourceId": 8094403,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
